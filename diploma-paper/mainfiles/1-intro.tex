%!TEX root = ../graduate-work.tex
\phantomsection
\section*{Введение} 
\addcontentsline{toc}{section}{Введение}
Внедрение глубокого обучения в критически важные для безопасности системы (safety-
critical systems) — от авионики и автономного вождения до медицинской диагностики и
управления энергосетями — создало фундаментальный парадокс. С одной стороны,
нейронные сети демонстрируют производительность, превосходящую человеческую, с
другой — они остаются "черными ящиками", подверженными катастрофическим сбоям
при незначительных возмущениях входных данных, известных как состязательные
примеры (adversarial examples)\cite{Guidotti2019Enhancing}. В отличие от традиционного программного
обеспечения, где логика задается явно, поведение нейронной сети определяется
миллионами весовых коэффициентов, что делает невозможным использование
классических методов тестирования для гарантии отсутствия ошибок. Формальная
верификация призвана решить эту проблему, предоставляя математическое
доказательство того, что сеть удовлетворяет заданным спецификациям для бесконечного
множества возможных входных данных.

\subsection{Формальная формулировка задачи верификации}

В наиболее общем виде задачу верификации нейронной сети можно определить как проблему 
доказательства выполнимости логического следования. 
Рассматривая нейронную сеть как функцию 
$f: \mathcal{D}_{in} \to \mathcal{D}_{out}$, где $\mathcal{D}_{in} \subseteq \mathbb{R}^n$ и $\mathcal{D}_{out} \subseteq \mathbb{R}^m$, 
мы стремимся проверить, что для любого входного вектора $\mathbf{x}$, 
удовлетворяющего некоторому предусловию $\phi(\mathbf{x})$, 
выходной вектор $\mathbf{y} = f(\mathbf{x})$ удовлетворяет постусловию $\psi(\mathbf{y})$.
Формально задача верификации заключается в проверке истинности утверждения:

$$\forall \mathbf{x} \in \mathcal{D}_{in}, \quad \phi(\mathbf{x}) \implies \psi(f(\mathbf{x}))$$

На практике верификаторы часто решают обратную задачу — задачу поиска контрпримера (falsification). 
Они пытаются найти такой вектор $\mathbf{x}$, для которого выполняется предусловие $\phi(\mathbf{x})$, 
но нарушается постусловие $\psi(f(\mathbf{x}))$. То есть, они проверяют выполнимость формулы (Satisfiability):

$$\exists \mathbf{x} \in \mathcal{D}_{in} : \phi(\mathbf{x}) \land \neg \psi(f(\mathbf{x}))$$

Если такая формула невыполнима (UNSAT), то свойство верифицировано. 
Если выполнима (SAT), то найденный $\mathbf{x}$ является состязательным примером или доказательством небезопасности системы.\cite{marzari2025advancingneuralnetworkverification}

\textbf{Спецификации локальной устойчивости и безопасности}

Наиболее распространенным классом свойств, верифицируемых в современных исследованиях, 
является локальная робастность (local robustness). Она подразумевает, что малые 
возмущения входного сигнала не должны изменять решение сети. 
Для задачи классификации с входным образом $\mathbf{x}_0$, классифицируемым как класс $c$, 
свойство робастности в $\epsilon$-окрестности по норме $L_p$ формулируется так:

\begin{itemize}
    \item \textbf{Предусловие} $\phi(\mathbf{x})$: $||\mathbf{x} - \mathbf{x}_0||_p \le \epsilon$. Это определяет гиперкуб (для $L_\infty$) или гиперсферу (для $L_2$) возможных входных данных.
    \item \textbf{Постусловие} $\psi(\mathbf{y})$: $\forall j \neq c, f(\mathbf{x})_c > f(\mathbf{x})_j$. Это означает, что оценка (логит) правильного класса $c$ должна оставаться строго больше оценок всех остальных классов. \cite{DBLP:journals/corr/abs-2002-03339}
\end{itemize}

Помимо робастности, существуют более сложные функциональные спецификации безопасности, часто применяемые в управлении. 
Примером служит система предотвращения столкновений ACAS Xu, где свойства формулируются в терминах физических переменных.\cite{Demarchi2023SupportingStandardization}

\subsection{Стандарт VNN-LIB: Унификация языка спецификаций}

До 2020 года развитие области сдерживалось фрагментацией: каждый
исследовательский инструмент использовал свой формат для описания нейронных сетей
и проверяемых свойств, что делало невозможным прямое сравнение
производительности. В ответ на это сообщество разработало стандарт VNN-LIB
(Verification of Neural Networks Library), который стал де-факто международным
стандартом для описания задач верификации.\cite{VNNLIBWebsite}
VNN-LIB базируется на философии SMT-LIB (стандарта для SMT-решателей) и
использует S-выражения для декларативного описания ограничений. Стандарт
определяет три ключевых компонента:
\begin{itemize}
    \item \textbf{Синтаксис запросов:} Позволяет определять входные и выходные переменные, их типы (Real, Int) и накладывать на них линейные и нелинейные ограничения.
    \item \textbf{Семантика:} Строго фиксирует интерпретацию логических связок (and, or, not, =>) и арифметических операций, устраняя двусмысленность при обработке различными решателями.
    \item \textbf{Интерфейс решателей:} Стандартизирует протокол взаимодействия между инструментами и тестовыми средами, что критически важно для автоматизации соревнований VNN-COMP.
\end{itemize}
Пример спецификации на языке VNN-LIB, описывающий ограничение входного значения X некоторым диапазоном и проверку того, что выход Y не превышает пороговое значение:
\begin{lstlisting}[caption={Пример SMT-LIB},label={lst:smtlib}]
    (declare-const X Real)
    (declare-const Y Real)
    (declare-const Y_out Real)
    ; Предусловие: вход в диапазоне
    (assert (>= X 0.0))
    (assert (<= X 1.0))
    ; Связь переменных (абстрактная)
    (assert (= Y_out (network_output X)))
    ; Постусловие (проверка на нарушение): выход > 5
    (assert (> Y_out 5.0))
\end{lstlisting}
Использование VNN-LIB в сочетании с форматом ONNX для обмена моделями нейронных
сетей позволило создать экосистему, в которой бенчмарки и инструменты могут
разрабатываться независимо друг от друга.\cite{arXiv2212VNNCOMP2022}

\subsection{Вычислительная сложность и теоретические ограничения}

Анализ вычислительной сложности задачи верификации раскрывает фундаментальные трудности, с которыми сталкиваются алгоритмы. 
Сложность напрямую зависит от типа функций активации, используемых в сети.
NP-полнота для ReLU-сетей:
Для сетей, использующих кусочно-линейные функции активации, такие как Rectified Linear Unit (ReLU: $\max(0, x)$), 
задача верификации доказана как NP-полная.\cite{arXiv2403RobustnessVerification}
\begin{itemize}
    \item \textbf{Доказательство:} Задача выполнимости булевых формул (3-SAT) может быть полиномиально сведена к задаче верификации ReLU-сети. Нейрон ReLU способен эмулировать логический вентиль, а слои сети — логическую схему. Поэтому в худшем случае время верификации экспоненциально возрастает относительно числа нейронов.
    \item \textbf{Последствия:} Это означает, что не существует полиномиального алгоритма, гарантирующего верификацию произвольной ReLU-сети (при условии, что $P \neq NP$). Однако аналогично SAT-решателям, многие практические инстансы задач обладают структурой, позволяющей решать их существенно быстрее худшего случая.
\end{itemize}

$\exists\mathbb{R}$-полнота и неразрешимость для нелинейных сетей:
Для сетей с гладкими нелинейными активациями (Sigmoid, Tanh, GELU) ситуация еще сложнее.
\begin{itemize}
    \item Задача верификации таких сетей относится к классу сложности $\exists\mathbb{R}$-complete (Existential Theory of the Reals).\cite{NeurIPS2021ExistsRComplete} Этот класс включает задачи, сводимые к поиску решений систем полиномиальных неравенств над вещественными числами. Он находится между NP и PSPACE.
    \item Более того, для некоторых классов рекуррентных сетей (RNN) или сетей с трансцендентными функциями задача достижимости может быть алгоритмически неразрешимой в общем виде.\cite{IJCAI2018ReachabilityDNN} Это накладывает теоретический предел на возможности полной верификации таких архитектур и вынуждает использовать методы аппроксимации (абстрактную интерпретацию), которые жертвуют полнотой ради разрешимости.
\end{itemize}
Таким образом, задача верификации представляет собой поиск баланса между выразительностью модели и вычислительной стоимостью доказательства её свойств.

